{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u22n2d1MbjW6",
        "outputId": "3e87fb31-c394-4871-f77c-a10ffa99d58f"
      },
      "outputs": [],
      "source": [
        "!pip install python_speech_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLOltoq7opN3",
        "outputId": "5ea550ae-8898-4b05-caed-f990fbc829ce"
      },
      "outputs": [],
      "source": [
        "!pip install image-classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khcp0u_yJMQL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from scipy.io import wavfile\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D,MaxPooling2D,Flatten,LSTM,BatchNormalization,GlobalAveragePooling2D\n",
        "from keras.layers import Dropout,Dense,TimeDistributed\n",
        "from keras.models import Sequential\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm import tqdm\n",
        "from python_speech_features import mfcc\n",
        "import pickle\n",
        "from keras.callbacks import ModelCheckpoint\n",
        " \n",
        "import librosa as lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3wH84isvy6rt",
        "outputId": "d68dabb6-7c82-4616-8dfb-11c7dae7d46e"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZI50B2Wbi0z"
      },
      "outputs": [],
      "source": [
        "# Set the random seed for TensorFlow and NumPy\n",
        "tf.random.set_seed(1)\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPKbqPPdJSEW",
        "outputId": "2594d7b7-f1b5-49a7-8a96-ded2125dadde"
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path('data/mini_speech_commands')\n",
        "if not data_dir.exists():\n",
        "  tf.keras.utils.get_file(\n",
        "      'mini_speech_commands.zip',\n",
        "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data')\n",
        " \n",
        "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
        "commands = commands[commands != 'README.md']\n",
        "print('Commands:', commands)\n",
        " \n",
        " \n",
        "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
        "filenames = tf.random.shuffle(filenames)\n",
        "num_samples = len(filenames)\n",
        "print('Number of total examples:', num_samples)\n",
        "print('Number of examples per label:',\n",
        "      len(tf.io.gfile.listdir(str(data_dir/commands[0]))))\n",
        "print('Example file tensor:', filenames[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfIB-0XhJWRn",
        "outputId": "9e16e3da-1485-44d7-e64e-73be7dca491f"
      },
      "outputs": [],
      "source": [
        "train_files = filenames[:6400]\n",
        "val_files = filenames[6400: 6400 + 1000]\n",
        "test_files = filenames[-600:]\n",
        " \n",
        "print('Training set size', len(train_files))\n",
        "print('Validation set size', len(val_files))\n",
        "print('Test set size', len(test_files))\n",
        " \n",
        " \n",
        "def decode_audio(audio_binary):\n",
        "  audio, _ = tf.audio.decode_wav(audio_binary)\n",
        "  return tf.squeeze(audio, axis=-1)\n",
        " \n",
        "def get_label(file_path):\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        " \n",
        "  # Note: You'll use indexing here instead of tuple unpacking to enable this \n",
        "  # to work in a TensorFlow graph.\n",
        "  return parts[-2] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kut1NFEwJZk5",
        "outputId": "47377c9a-cae7-4c7b-c3f0-3f3897766610"
      },
      "outputs": [],
      "source": [
        "def get_waveform_and_label(file_path):\n",
        "  label = get_label(file_path)\n",
        "  print(\"label\")\n",
        "  print(label)\n",
        "  audio_binary = tf.io.read_file(file_path)\n",
        "  waveform = decode_audio(audio_binary)\n",
        "  print(\"waveform\")\n",
        "  print(waveform)\n",
        "  return waveform, label\n",
        " \n",
        " \n",
        " \n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "files_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
        "waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
        " \n",
        " \n",
        " \n",
        "rows = 3\n",
        "cols = 3\n",
        "n = rows*cols\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(10, 12))\n",
        "for i, (audio, label) in enumerate(waveform_ds.take(n)):\n",
        "  r = i // cols\n",
        "  c = i % cols\n",
        "  ax = axes[r][c]\n",
        "  ax.plot(audio.numpy())\n",
        "  ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n",
        "  label = label.numpy().decode('utf-8')\n",
        "  ax.set_title(label)\n",
        " \n",
        "plt.show()\n",
        " \n",
        " \n",
        " \n",
        "def get_spectrogram(waveform):\n",
        "  # Padding for files with less than 16000 samples\n",
        "  zero_padding = tf.zeros([16000] - tf.shape(waveform), dtype=tf.float32)\n",
        " \n",
        "  # Concatenate audio with padding so that all audio clips will be of the \n",
        "  # same length\n",
        "  waveform = tf.cast(waveform, tf.float32)\n",
        "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
        "  spectrogram = tf.signal.stft(\n",
        "      equal_length, frame_length=255, frame_step=128)\n",
        "      \n",
        "  spectrogram = tf.abs(spectrogram)\n",
        " \n",
        "  return spectrogram\n",
        " \n",
        " \n",
        "for waveform, label in waveform_ds.take(1):\n",
        "  label = label.numpy().decode('utf-8')\n",
        "  spectrogram = get_spectrogram(waveform)\n",
        " \n",
        "print('Label:', label)\n",
        "print('Waveform shape:', waveform.shape)\n",
        "print('Spectrogram shape:', spectrogram.shape)\n",
        "print('Audio playback')\n",
        "display.display(display.Audio(waveform, rate=16000))\n",
        " \n",
        " \n",
        "def plot_spectrogram(spectrogram, ax):\n",
        "  # Convert to frequencies to log scale and transpose so that the time is\n",
        "  # represented in the x-axis (columns).\n",
        "  log_spec = np.log(spectrogram.T)\n",
        "  height = log_spec.shape[0]\n",
        "  width = log_spec.shape[1]\n",
        "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
        "  Y = range(height)\n",
        "  ax.pcolormesh(X, Y, log_spec)\n",
        " \n",
        " \n",
        "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
        "timescale = np.arange(waveform.shape[0])\n",
        "axes[0].plot(timescale, waveform.numpy())\n",
        "axes[0].set_title('Waveform')\n",
        "axes[0].set_xlim([0, 16000])\n",
        "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
        "axes[1].set_title('Spectrogram')\n",
        "plt.show()\n",
        " \n",
        " \n",
        "def get_spectrogram_and_label_id(audio, label):\n",
        "  spectrogram = get_spectrogram(audio)\n",
        "  spectrogram = tf.expand_dims(spectrogram, -1)\n",
        "  label_id = tf.argmax(label == commands)\n",
        "  return spectrogram, label_id\n",
        " \n",
        " \n",
        "spectrogram_ds = waveform_ds.map(\n",
        "    get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
        " \n",
        " \n",
        "rows = 3\n",
        "cols = 3\n",
        "n = rows*cols\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
        "for i, (spectrogram, label_id) in enumerate(spectrogram_ds.take(n)):\n",
        "  r = i // cols\n",
        "  c = i % cols\n",
        "  ax = axes[r][c]\n",
        "  plot_spectrogram(np.squeeze(spectrogram.numpy()), ax)\n",
        "  ax.set_title(commands[label_id.numpy()])\n",
        "  ax.axis('off')\n",
        "  \n",
        "plt.show()\n",
        " \n",
        " \n",
        "def preprocess_dataset(files):\n",
        "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
        "  output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
        "  output_ds = output_ds.map(\n",
        "      get_spectrogram_and_label_id,  num_parallel_calls=AUTOTUNE)\n",
        "  return output_ds\n",
        " \n",
        " \n",
        "train_ds = spectrogram_ds\n",
        "val_ds = preprocess_dataset(val_files)\n",
        "test_ds = preprocess_dataset(test_files)\n",
        "print(\"test_ds\")\n",
        "print(type(train_ds)) \n",
        " \n",
        "batch_size = 64\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "val_ds = val_ds.batch(batch_size)\n",
        "test_ds = test_ds.batch(batch_size) \n",
        " \n",
        "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G-TeIYUJdJv",
        "outputId": "afe782ae-9dde-4760-8352-b761b603d1dd"
      },
      "outputs": [],
      "source": [
        "iterator = train_ds.__iter__()\n",
        "next_element = iterator.get_next()\n",
        "pt = next_element[0]\n",
        "en = next_element[1]\n",
        "print(pt.numpy().shape)\n",
        "print(en.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E9Y8ucDJevt",
        "outputId": "0588aa48-dac6-4379-f9fa-6a73ec5f7ca3"
      },
      "outputs": [],
      "source": [
        "iterator1 = val_ds.__iter__()\n",
        "next_element1 = iterator1.get_next()\n",
        "pt1 = next_element1[0]\n",
        "en1 = next_element1[1]\n",
        "print(pt1.numpy().shape)\n",
        "print(en1.numpy().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FseP7xZJgdL",
        "outputId": "1d2d43a5-8e5c-467b-d147-071eb9fcbe8d"
      },
      "outputs": [],
      "source": [
        "for spectrogram, _ in spectrogram_ds.take(1):\n",
        "  input_shape = spectrogram.shape\n",
        "print('Input shape:', input_shape)\n",
        "num_labels = len(commands)\n",
        "\n",
        "norm_layer = preprocessing.Normalization()\n",
        "norm_layer.adapt(spectrogram_ds.map(lambda x, _: x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1EViQPkJiCO"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQg-8Udtvjxg",
        "outputId": "ee4cc1df-0cf7-4414-ff4a-a8d6d204039e"
      },
      "outputs": [],
      "source": [
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y6U03BWbsCk"
      },
      "outputs": [],
      "source": [
        "def preprocess(spectrogram, label):\n",
        "    spectrogram = tf.repeat(spectrogram, repeats=3, axis=-1)\n",
        "    return spectrogram, label\n",
        "\n",
        "spectrogram_ds = spectrogram_ds.map(preprocess)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh5GPwy-fZpD",
        "outputId": "f36d9f85-507f-4620-8bca-3db044e14f22"
      },
      "outputs": [],
      "source": [
        "spectrogram_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91l_5g-ElQ78"
      },
      "outputs": [],
      "source": [
        "num_val_samples = 1000\n",
        "# Split spectrogram_ds into train_ds and val_ds\n",
        "train_ds = spectrogram_ds.skip(num_val_samples)\n",
        "val_ds = spectrogram_ds.take(num_val_samples)\n",
        "test_split = 0.6\n",
        "# Further split val_ds into val_ds and test_ds\n",
        "num_test_samples = int(num_val_samples * test_split)\n",
        "test_ds = val_ds.take(num_test_samples)\n",
        "val_ds = val_ds.skip(num_test_samples)\n",
        "\n",
        "# Set batch size and shuffle the train_ds\n",
        "batch_size = 64\n",
        "train_ds = train_ds.shuffle(buffer_size=1000).batch(batch_size)\n",
        "test_ds = test_ds.batch(batch_size)\n",
        "val_ds = val_ds.batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7A8qp9cbi04"
      },
      "outputs": [],
      "source": [
        "# Define a function to extract the labels from the dataset\n",
        "def get_label(spectrogram, label):\n",
        "    return label\n",
        "\n",
        "# Map the get_label function to the train_ds to extract the labels\n",
        "train_labels_ds = train_ds.map(get_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRBo3IUYbi04",
        "outputId": "44c903bd-fe4b-4604-fc3a-23f4789cbd45"
      },
      "outputs": [],
      "source": [
        "test_labels_ds = test_ds.map(get_label)\n",
        "test_labels_ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq6wXBGa0qbR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import Xception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjc7Chru6dNL",
        "outputId": "07b97980-b2fd-4880-bb73-faf747a5de71"
      },
      "outputs": [],
      "source": [
        "# VGG19\n",
        "# Define the input shape\n",
        "input_shape = (124, 129, 3)\n",
        "\n",
        "# Define the VGG19 model with pre-trained weights\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a custom head to the model\n",
        "x = layers.Flatten()(base_model.output)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(num_labels, activation='softmax')(x)\n",
        "\n",
        "# Compile the model\n",
        "vgg19_model = models.Model(inputs=base_model.input, outputs=output)\n",
        "vgg19_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "print(\"VGG19\")\n",
        "# Train the model on the train dataset\n",
        "vgg19_model.fit(train_ds, epochs=50, validation_data=val_ds, callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8djwcRv6dV2",
        "outputId": "c55fe70b-9adc-477a-c607-4934c7bd17fe"
      },
      "outputs": [],
      "source": [
        "# VGG16\n",
        "# Define the input shape\n",
        "input_shape = (124, 129, 3)\n",
        "\n",
        "# Define the VGG16 model with pre-trained weights\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a custom head to the model\n",
        "x = layers.Flatten()(base_model.output)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(num_labels, activation='softmax')(x)\n",
        "\n",
        "# Compile the model\n",
        "vgg16_model = models.Model(inputs=base_model.input, outputs=output)\n",
        "vgg16_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "print(\"VGG16\")\n",
        "# Train the model on the train dataset\n",
        "vgg16_model.fit(train_ds, epochs=50, validation_data=val_ds, callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PfH58epgcYb",
        "outputId": "441353e8-4997-4382-8d4a-ab4cd985f57b"
      },
      "outputs": [],
      "source": [
        "# RESNET50\n",
        "# Define the input shape\n",
        "input_shape = (124, 129, 3)\n",
        "\n",
        "# Define the ResNet50 model with pre-trained weights\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Add a custom head to the model\n",
        "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(num_labels, activation='softmax')(x)\n",
        "\n",
        "# Compile the model\n",
        "resnet_model = models.Model(inputs=base_model.input, outputs=output)\n",
        "resnet_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.00015), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print(\"ResNet50\")\n",
        "# Train the model on the train dataset\n",
        "resnet_model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViDfepakgdiD",
        "outputId": "891349c0-8c52-4997-dc6e-9243b29d0d6c"
      },
      "outputs": [],
      "source": [
        "# INCEPTIONV3\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (124, 129, 3)\n",
        "\n",
        "# Define the InceptionV3 model with pre-trained weights\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Add a custom head to the model\n",
        "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(num_labels, activation='softmax')(x)\n",
        "\n",
        "# Compile the model\n",
        "inception_model = models.Model(inputs=base_model.input, outputs=output)\n",
        "inception_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.00017), metrics=['accuracy'])\n",
        "\n",
        "print(\"InceptionV3\")\n",
        "# Train the model on the train dataset\n",
        "inception_model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaMxormdgs4J",
        "outputId": "b6a5adb9-0e17-46bd-9a4e-bfc69cabfa89"
      },
      "outputs": [],
      "source": [
        "# XCEPTION\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (124, 129, 3)\n",
        "\n",
        "# Define the Xception model with pre-trained weights\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze all layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Add a custom head to the model\n",
        "x = layers.Flatten()(base_model.output)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(num_labels, activation='softmax')(x)\n",
        "\n",
        "# Compile the model\n",
        "xception_model = models.Model(inputs=base_model.input, outputs=output)\n",
        "xception_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.00001), metrics=['accuracy'])\n",
        "\n",
        "print(\"Xception\")\n",
        "# Train the model on the train dataset\n",
        "xception_model.fit(train_ds, epochs=80, validation_data=val_ds, callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=1))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "0bd6827e5b9b024a8afcecbb4b32b3f39bbe94aa5ba060866c09f0f3ec848126"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
